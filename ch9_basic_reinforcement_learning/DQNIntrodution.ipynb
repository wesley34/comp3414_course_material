{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQNIntrodution.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpxBNVePDHhNMIFJKkTCbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesley34/comp3414_course_material/blob/master/ch_9_basic_reinforcement_learning/DQNIntrodution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73TbFqbMeJlf",
        "colab_type": "text"
      },
      "source": [
        "### Welcome to DQN starter kit, you will learn how to make a deep reinforcemnt learning with simulator here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28I9EFmYe4Q9",
        "colab_type": "text"
      },
      "source": [
        "### I would provide intuition with some math in a very brief sense\n",
        "\n",
        "1.   To help you to at least know what is nerual network in a very brief sense\n",
        "2.   To help you to know how to make a simulaotr\n",
        "3.   To help you to code a very simple DQN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUwvli85fYfN",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 : Simulator\n",
        "### Explore on https://gym.openai.com/docs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVjPU15OeVD_",
        "colab_type": "text"
      },
      "source": [
        "### Keyword\n",
        "\n",
        "\n",
        "1.   state : observation from the environment(simulator)\n",
        "2.   action : agents' action\n",
        "3.   reward : scores you get from the simulator with some special calculation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3648Aeid7up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required libaray\n",
        "import gym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oySd9nLofeLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v0\") # env stands for environment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJP6N7YyfgH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b0f85b5-a8b8-478a-a3d3-f3a6fc1412ca"
      },
      "source": [
        "print(env.observation_space) # \"bot\" observes 4 things in this simulator\n",
        "## you may check the meaning behind the numbers -> go explore yourself now"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Box(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYti3GnPfpiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2633600d-d0ba-46ec-facf-d6df169b1fcc"
      },
      "source": [
        "env.reset() # environment reset that means we open a new round of game (as the bot will die)\n",
        "# it will return a new observation (size of 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0207832 ,  0.02326512,  0.0427209 , -0.00041564])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnuodTuQgPc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cb43fa1-e245-4b12-fb49-ec2f66a42095"
      },
      "source": [
        "print(env.action_space) # bot has 2 option on moving"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discrete(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAFm62iggnB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4ca651eb-e638-410a-cbea-182e701a2503"
      },
      "source": [
        "print(env.step(0)) # move first action\n",
        "print(env.step(1)) # move second action"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([ 0.01779965, -0.36814642,  0.04882127,  0.61127589]), 1.0, False, {})\n",
            "(array([ 0.01043672, -0.17373961,  0.06104679,  0.33436089]), 1.0, False, {})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CzoXJjVhCtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the meaning behind the return\n",
        "observation, reward , is_done, extra_info = env.step(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XEHta4ThONx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e581b65a-6b6f-4367-9c8a-24ba5e463918"
      },
      "source": [
        "# reset the env before start\n",
        "total_reward = 0.0\n",
        "env.reset()\n",
        "for _ in range(1000):\n",
        "  # if you want to render the things\n",
        "  # env.render() if cannot be run in colab but you may render it with normal IDE or special tatics in colab :)\n",
        "  act = env.action_space.sample()\n",
        "  obs, reward, is_done ,_ = env.step(act) # no extra info for this one\n",
        "  total_reward += reward\n",
        "  if is_done: # when you die you end \n",
        "    break\n",
        "# if you get 200+ that means you are super lucky ! \n",
        "# good luck if you get 60+\n",
        "# otherwise please keep looking :>\n",
        "print(total_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EF2yuVPiAQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sK_Ku4JidUr",
        "colab_type": "text"
      },
      "source": [
        "## Deep learning\n",
        "#### Not much math here or it is another course :)\n",
        "\n",
        "*   We use deep learning for modelling in DQN, you may also use others and you may explore them : what is the good or bad things of those algorithm\n",
        "*   (Explore) Loss function , it calculates how much infomation you ignore or how bad it is your prediction result compare to the actual one. The common one is called mean square error : (L2 loss): 1/2 * (prediciton-real)^2\n",
        "*   (Explore) Backward propagation , Intuition :  Base on you loss , it will use \"Math\" to correct you model parameter\n",
        "*   (Explore) model parameter , or weightings: It is used to multiply the incoming data, so it will keep updating with backward propagation\n",
        "*   (Explore) activation function: it helps you to filter \"useless\" data or provide non-linearlity to the model as the problem is always not a linear problem. (There are many usage for activation function not limit to this 2)\n",
        "\n",
        "\n",
        "---\n",
        "The flow on Deep learning\n",
        "\n",
        "*   Data -> model -> prediction -> correct the model -> repeat ( basic flow of machine learning)\n",
        "*   We only focus on modelling as the data preprocessing part in our problem is not much important at this moment (thats another statistic course :>)\n",
        "*   We focus on model\n",
        "*   (Data)-> multiply with weighings -> activation function -> new Data -> repeat (Common practise, but you may design a complex structure with spliting / routing / ...)\n",
        "*   The data and te weightings are in matrix form , hence the size of the data can change easily : Data is 10 * 9 , weight is 9 * 1 , outcome is 10 * 9 * 9 * 1 = 10*1\n",
        "*   Eventually, it will output a prediction \n",
        "*   We do not know what it is inside , or what is it doing, aka black box machine learning, (but indeed we can :> )\n",
        "\n",
        "\n",
        "---\n",
        "check some photo here to help you understanding https://www.newworldai.com/what-is-deep-learning-nature-of-machine-learning-and-beauty-of-deep-neural-networks/ \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJnSrTBpnM7j",
        "colab_type": "text"
      },
      "source": [
        "## Converge\n",
        "#### why the answer will come out\n",
        "https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html\n",
        "\n",
        "*   Gradient Descent \n",
        "*   (Explore , again it will be another course :> )There are many topics and skills related to them\n",
        "*   Intuition : You want to buy a stock , you want to buy at the loweset. Similarly, we have cost in model, either maximize it or minimize it, we want to find out that point (local / Global). Gradient Descent helps us to draw a line to lead us to find the goal point given that we do not know where the goal point of the cost.\n",
        "*   Check the math , it should not be difficult :> And please at least understand stochastic gradient descent, if better please understand stochastic in a brief sense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyz-9dTki6_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## but it takes you a lot of time to tunning, fine-tunning and even create a new architecture\n",
        "## the most common type architecture will be cnn,rnn,encoder ...\n",
        "## and for each type there are a lot of implementations and creation, you may explore more but I think you already know all of them :>\n",
        "## if possible please read the math on it and try to understand the backward propagation in a math sense which takes you the knowledges in\n",
        "## partial-D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH_PNR4dm15r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxoex7fUpEie",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning + Gym + reinforcement learning ==>  deep reinforcemnt learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnIgynlppVzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Now we will create a deep learning model for the simulator \n",
        "### we will use pytorch here\n",
        "### some explanation will be made\n",
        "### tensorflow will be use later, as pytorch is more dynamic and good for reinforcement learning framework"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud5AIb7gpjgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8__r7VUraGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlGOwlfTpgOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module): #extend nn.module\n",
        "  def __init__(self,observation_shape,action_shape): # constructor:\n",
        "    super(DQN,self).__init__() # call parent constructor\n",
        "\n",
        "    # we make a simple cnn architecture\n",
        "    # nn.Sequntial is used to make a model\n",
        "    # the layer will follow this setting to run \n",
        "\n",
        "    self.convolution_net = nn.Sequential( \n",
        "        nn.Conv2d(input_shape[0],32,kernel_size=7,stride=4), # check CNN yourself :>\n",
        "        nn.ReLU(), # activation function  , check it youself :> , it is a light strategy to clear some not important message\n",
        "        nn.Conv2d(32,64,kernel=4,stride=2),# btw, nn.Conv2d(input_channel,output_channel,kernel_size,stride_number) , channel means size , you should know and check it yourself :>\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64,64,kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    # optional \n",
        "    # no batch norm, no pooling , have nothing in later preprocess, I m irresponsible as you know, check it yourself!\n",
        "    # check why we need batch_norm, pooling , kinds of pooling , etc ... if you want to know more\n",
        "    # check stride effect, check dilation , check variance on graphics ... if you want to know more\n",
        "    \n",
        "    \n",
        "  \n",
        "    conv_out_size = self._get_conv_output_shape(input_shape)\n",
        "\n",
        "    self.fully_connected_net  = nn.Sequential(\n",
        "        nn.Linear(conv_out_size,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,n.actions) # Linear means normal structure of Deep learning\n",
        "    )\n",
        "\n",
        "    def _get_conv_output_shape(self,shaoe):\n",
        "      output = self.conv(torch.zeros(1,*shape)) # *shape is a special way to pass in argument, should be learnt in 1330 :>\n",
        "      return int(np.prod(output.size)) #np.prod means product , here it means 1*output_size , as output.size is (1,output_size)\n",
        "    # override function\n",
        "    def forward(self,x):\n",
        "      conv_out = self.convolution_net(x) # pass data to convolutional neural network\n",
        "      # [channel,width,height] -> [channel,width*height] , as nn.Linear takes 2D data but cnn output 3d data\n",
        "      conv_out = conv_out.view(x.size[0],-1)\n",
        "      return self.fully_connected_net(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_uVSFbsK9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN\n",
        "# in a brief sense,\n",
        "# you have some images , you want to find some smaller images/pattern from them\n",
        "# those pattern can help you understand more on the graph/pictures\n",
        "# say, you wanna to detect from dog/cat\n",
        "# the pattern formed due to deep learning is a cat-ear / dog-ear\n",
        "# you know the pattern is in batches (that means a set of pattern)\n",
        "# use those batches of pattern to compare with upcomming photo\n",
        "# if the incomming photo matches with the cat-ear kernel -> then the probability of it being a cat will be increased\n",
        "# if the incomming photo matches with the dog-ear kernel -> then the probability of it being a dog will be increased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZgVVHXTqA2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create our agent now\n",
        "class Agent:\n",
        "  def __init__(self,env.exp_replay_buffer): # constructor\n",
        "    self.env = env\n",
        "    self.exp_buffer = exp_buffer\n",
        "    # telling agent it is the start of the game\n",
        "    self._reset()\n",
        "  \n",
        "  def _reset(self):\n",
        "    self.state = env.reset()\n",
        "    self.total_reward = 0\n",
        "  \n",
        "  def play_step(self,net,epsilon=0.0,device=\"cpu\"):\n",
        "\n",
        "    if np.random.random() < epsilon:\n",
        "      action = env.action_space.sample()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}